{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('timesofindia_train.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_embeddings(path):\n",
    "    embeddings_index = dict()\n",
    "    f = open(path)\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "    f.close()\n",
    "    return embeddings_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_300d = word_embeddings(\"/home/user/Desktop/timesofindiatrainfiles/glove.6B/glove.6B.300d.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sent = (df['sentence'].str.len() > 10)\n",
    "ne_df = df.loc[df_sent]\n",
    "df = ne_df\n",
    "df = df[~df.sentence.str.startswith('https')]\n",
    "df = df[~df.sentence.str.startswith('url : ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1323\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "sent_list = []\n",
    "label_list = []\n",
    "\n",
    "sent_list = df[\"sentence\"].tolist()\n",
    "label_list = df[\"etype\"].tolist()\n",
    "\n",
    "print(len(label_list))\n",
    "print(label_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create sequence\n",
    "first_1000 = df['sentence']\n",
    "label_list = df['etype']\n",
    "vocabulary_size = 20000\n",
    "tokenizer = Tokenizer(num_words= vocabulary_size)\n",
    "tokenizer.fit_on_texts(first_1000)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(first_1000)\n",
    "data = pad_sequences(sequences, maxlen=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((vocabulary_size, 300))\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    if index > vocabulary_size - 1:\n",
    "        break\n",
    "    else:\n",
    "        embedding_vector = glove_300d.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[index] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, label_list, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_glove = Sequential()\n",
    "model_glove.add(Embedding(vocabulary_size, 300, input_length=200, weights=[embedding_matrix], trainable=False))\n",
    "model_glove.add(Dropout(0.2))\n",
    "model_glove.add(Conv1D(64, 5, activation='relu'))\n",
    "model_glove.add(MaxPooling1D(pool_size=4))\n",
    "model_glove.add(LSTM(200))\n",
    "model_glove.add(Dense(1, activation='sigmoid'))\n",
    "model_glove.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "886/886 [==============================] - 6s 7ms/step - loss: 0.5939 - acc: 0.7212\n",
      "Epoch 2/10\n",
      "886/886 [==============================] - 4s 5ms/step - loss: 0.4517 - acc: 0.7833\n",
      "Epoch 3/10\n",
      "886/886 [==============================] - 4s 5ms/step - loss: 0.3547 - acc: 0.8499\n",
      "Epoch 4/10\n",
      "886/886 [==============================] - 4s 5ms/step - loss: 0.2923 - acc: 0.8758\n",
      "Epoch 5/10\n",
      "886/886 [==============================] - 4s 5ms/step - loss: 0.2301 - acc: 0.8962\n",
      "Epoch 6/10\n",
      "886/886 [==============================] - 4s 5ms/step - loss: 0.1214 - acc: 0.9628\n",
      "Epoch 7/10\n",
      "886/886 [==============================] - 4s 5ms/step - loss: 0.0728 - acc: 0.9808\n",
      "Epoch 8/10\n",
      "886/886 [==============================] - 4s 5ms/step - loss: 0.0247 - acc: 0.9932\n",
      "Epoch 9/10\n",
      "886/886 [==============================] - 4s 5ms/step - loss: 0.0402 - acc: 0.9910\n",
      "Epoch 10/10\n",
      "886/886 [==============================] - 4s 5ms/step - loss: 0.0442 - acc: 0.9876\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6575d514a8>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_glove.fit(X_train, np.array(y_train), validation_split=0.0, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model_glove.predict(X_test)\n",
    "prediction = [1 if pred>0.5 else 0 for pred in prediction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6925795053003533\n",
      "0.8009153318077803\n",
      "0.6533333333333333\n",
      "0.7368421052631579\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "print(f1_score(y_test, prediction))\n",
    "print(accuracy_score(y_test, prediction))\n",
    "print(precision_score(y_test, prediction))\n",
    "print(recall_score(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
